#!/usr/bin/env python3
"""
å›å¡« Tushare Daily Basic æ¯æ—¥æŒ‡æ ‡æ•°æ®

ä¸ºç°æœ‰å†å²æ•°æ®å›å¡« daily_basic æŒ‡æ ‡ï¼ˆPEã€PBã€å¸‚å€¼ç­‰ï¼‰ï¼Œåªè·å– daily_basic æ•°æ®ï¼Œ
ä¸é‡å¤è·å– daily å’Œ adj_factor æ•°æ®ï¼Œä½¿ç”¨ UPDATE è¯­å¥æ›´æ–°ç°æœ‰è®°å½•ã€‚

ä½¿ç”¨æ–¹æ³•:
    # å›å¡«æ‰€æœ‰è‚¡ç¥¨
    python scripts/backfill_daily_basic.py

    # å›å¡«æŒ‡å®šæ—¥æœŸèŒƒå›´
    python scripts/backfill_daily_basic.py --start-date 20230101 --end-date 20240101

    # å›å¡«æŒ‡å®šè‚¡ç¥¨
    python scripts/backfill_daily_basic.py --stocks 000001,600000

    # ä»æ–‡ä»¶è¯»å–è‚¡ç¥¨åˆ—è¡¨
    python scripts/backfill_daily_basic.py --stocks stocks.txt

    # ç»§ç»­ä¸Šæ¬¡çš„å›å¡«
    python scripts/backfill_daily_basic.py --resume

    # æŸ¥çœ‹å¸®åŠ©
    python scripts/backfill_daily_basic.py --help
"""
import argparse
import sys
import os
import json
from pathlib import Path
from datetime import datetime
import pandas as pd
from sqlalchemy import text

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data_sources.tushare import TushareDB


def get_stocks_need_backfill(db):
    """
    è·å–éœ€è¦å›å¡« daily_basic æ•°æ®çš„è‚¡ç¥¨åˆ—è¡¨

    Returns:
        list: éœ€è¦å›å¡«çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    query = """
    SELECT DISTINCT symbol
    FROM bars
    WHERE pe IS NULL
      AND pb IS NULL
      AND total_mv IS NULL
      AND interval = '1d'
    ORDER BY symbol
    """
    try:
        with db.engine.connect() as conn:
            df = pd.read_sql_query(query, conn)
        if not df.empty:
            return df['symbol'].tolist()
        return []
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢éœ€è¦å›å¡«çš„è‚¡ç¥¨å¤±è´¥: {e}")
        return []


def get_stock_date_range(db, symbol):
    """
    è·å–è‚¡ç¥¨çš„æ•°æ®æ—¥æœŸèŒƒå›´

    Args:
        db: TushareDB å®ä¾‹
        symbol: è‚¡ç¥¨ä»£ç 

    Returns:
        tuple: (start_date, end_date) æ ¼å¼ä¸º YYYYMMDDï¼Œå¦‚æœæ²¡æœ‰æ•°æ®è¿”å› (None, None)
    """
    query = """
    SELECT MIN(datetime) as min_date, MAX(datetime) as max_date
    FROM bars
    WHERE symbol = :symbol
      AND interval = '1d'
    """
    try:
        with db.engine.connect() as conn:
            df = pd.read_sql_query(query, conn, params={"symbol": symbol})
        if not df.empty and df['min_date'].iloc[0] is not None:
            start_date = pd.to_datetime(df['min_date'].iloc[0]).strftime("%Y%m%d")
            end_date = pd.to_datetime(df['max_date'].iloc[0]).strftime("%Y%m%d")
            return start_date, end_date
        return None, None
    except Exception as e:
        print(f"  âš ï¸  {symbol} è·å–æ—¥æœŸèŒƒå›´å¤±è´¥: {e}")
        return None, None


def get_existing_dates_with_basic(db, symbol):
    """
    è·å–å·²æœ‰ daily_basic æ•°æ®çš„æ—¥æœŸåˆ—è¡¨

    Args:
        db: TushareDB å®ä¾‹
        symbol: è‚¡ç¥¨ä»£ç 

    Returns:
        set: å·²æœ‰æ•°æ®çš„æ—¥æœŸé›†åˆ
    """
    query = """
    SELECT datetime
    FROM bars
    WHERE symbol = :symbol
      AND interval = '1d'
      AND pe IS NOT NULL
    """
    try:
        with db.engine.connect() as conn:
            df = pd.read_sql_query(query, conn, params={"symbol": symbol})
        if not df.empty:
            return set(pd.to_datetime(df['datetime']).dt.strftime("%Y-%m-%d"))
        return set()
    except Exception as e:
        print(f"  âš ï¸  {symbol} æŸ¥è¯¢å·²æœ‰æ•°æ®å¤±è´¥: {e}")
        return set()


def backfill_stock(db, symbol, start_date=None, end_date=None, skip_existing=True):
    """
    å›å¡«å•åªè‚¡ç¥¨çš„ daily_basic æ•°æ®

    Args:
        db: TushareDB å®ä¾‹
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ YYYYMMDDï¼ŒNone åˆ™è‡ªåŠ¨æ£€æµ‹
        end_date: ç»“æŸæ—¥æœŸ YYYYMMDDï¼ŒNone åˆ™è‡ªåŠ¨æ£€æµ‹
        skip_existing: æ˜¯å¦è·³è¿‡å·²æœ‰æ•°æ®çš„æ—¥æœŸ

    Returns:
        dict: {'success': bool, 'updated': int, 'skipped': int}
    """
    # æ ‡å‡†åŒ–ä»£ç 
    try:
        ts_code = db._standardize_code(symbol)
    except Exception as e:
        return {'success': False, 'updated': 0, 'skipped': 0, 'error': str(e)}

    # è‡ªåŠ¨æ£€æµ‹æ—¥æœŸèŒƒå›´
    if start_date is None or end_date is None:
        detected_start, detected_end = get_stock_date_range(db, ts_code.split('.')[0])
        if start_date is None:
            start_date = detected_start
        if end_date is None:
            end_date = detected_end

    if start_date is None or end_date is None:
        return {'success': False, 'updated': 0, 'skipped': 0, 'error': 'æ— æ³•æ£€æµ‹æ—¥æœŸèŒƒå›´'}

    # è·å–å·²æœ‰æ•°æ®çš„æ—¥æœŸ
    existing_dates = set()
    if skip_existing:
        existing_dates = get_existing_dates_with_basic(db, ts_code.split('.')[0])

    try:
        # è·å– daily_basic æ•°æ®
        basic = db._retry_api_call(
            db.pro.daily_basic,
            ts_code=ts_code,
            start_date=start_date,
            end_date=end_date,
            fields='ts_code,trade_date,turnover_rate,turnover_rate_f,volume_ratio,pe,pe_ttm,pb,ps,ps_ttm,dv_ratio,dv_ttm,total_share,float_share,free_share,total_mv,circ_mv'
        )

        if basic is None or basic.empty:
            return {'success': True, 'updated': 0, 'skipped': 0}

        # è¿‡æ»¤å·²æœ‰æ•°æ®
        if skip_existing and existing_dates:
            basic['trade_date_formatted'] = pd.to_datetime(basic['trade_date']).dt.strftime("%Y-%m-%d")
            basic = basic[~basic['trade_date_formatted'].isin(existing_dates)]
            existing_count = len(existing_dates)
            basic = basic.drop(columns=['trade_date_formatted'])
        else:
            existing_count = 0

        if basic.empty:
            return {'success': True, 'updated': 0, 'skipped': len(existing_dates)}

        # å‡†å¤‡æ›´æ–°æ•°æ®
        updates = []
        code = ts_code.split('.')[0]

        for _, row in basic.iterrows():
            trade_date = pd.to_datetime(row['trade_date']).strftime("%Y-%m-%d")
            update_data = {
                'symbol': code,
                'datetime': trade_date,
                'turnover': row.get('turnover_rate'),
                'turnover_rate_f': row.get('turnover_rate_f'),
                'volume_ratio': row.get('volume_ratio'),
                'pe': row.get('pe'),
                'pe_ttm': row.get('pe_ttm'),
                'pb': row.get('pb'),
                'ps': row.get('ps'),
                'ps_ttm': row.get('ps_ttm'),
                'dv_ratio': row.get('dv_ratio'),
                'dv_ttm': row.get('dv_ttm'),
                'total_mv': row.get('total_mv'),
                'circ_mv': row.get('circ_mv'),
                'total_share': row.get('total_share'),
                'float_share': row.get('float_share'),
                'free_share': row.get('free_share'),
            }
            updates.append(update_data)

        # æ‰¹é‡æ›´æ–°æ•°æ®åº“
        updated_count = 0
        with db.engine.connect() as conn:
            for update_data in updates:
                try:
                    # æ„å»º UPDATE è¯­å¥
                    set_clauses = []
                    params = {'symbol': update_data['symbol'], 'datetime': update_data['datetime']}

                    for key, value in update_data.items():
                        if key not in ['symbol', 'datetime'] and value is not None:
                            set_clauses.append(f"{key} = :{key}")
                            params[key] = value

                    if set_clauses:
                        sql = f"""
                        UPDATE bars
                        SET {', '.join(set_clauses)}
                        WHERE symbol = :symbol AND datetime = :datetime AND interval = '1d'
                        """
                        result = conn.execute(text(sql), params)
                        updated_count += result.rowcount
                except Exception as e:
                    pass  # è·³è¿‡æ›´æ–°å¤±è´¥çš„è®°å½•

            conn.commit()

        return {
            'success': True,
            'updated': updated_count,
            'skipped': existing_count
        }

    except Exception as e:
        error_msg = str(e)
        if "æ— æƒé™" in error_msg or "æƒé™" in error_msg or "403" in error_msg:
            return {'success': False, 'updated': 0, 'skipped': 0, 'error': 'æ— æƒé™ï¼ˆéœ€è¦2000+ç§¯åˆ†ï¼‰'}
        return {'success': False, 'updated': 0, 'skipped': 0, 'error': error_msg}


def save_checkpoint(checkpoint_path: str, data: dict):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    try:
        with open(checkpoint_path, 'w') as f:
            json.dump(data, f, indent=2)
    except Exception as e:
        print(f"  âš ï¸  ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")


def load_checkpoint(checkpoint_path: str) -> dict:
    """åŠ è½½æ£€æŸ¥ç‚¹"""
    try:
        if Path(checkpoint_path).exists():
            with open(checkpoint_path, 'r') as f:
                return json.load(f)
    except Exception as e:
        print(f"  âš ï¸  åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    return {}


def main():
    parser = argparse.ArgumentParser(
        description='å›å¡« Tushare Daily Basic æ¯æ—¥æŒ‡æ ‡æ•°æ®',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                                    # å›å¡«æ‰€æœ‰è‚¡ç¥¨
  %(prog)s --start-date 20230101             # æŒ‡å®šå¼€å§‹æ—¥æœŸ
  %(prog)s --start-date 20230101 --end-date 20240101  # æŒ‡å®šæ—¥æœŸèŒƒå›´
  %(prog)s --stocks 000001,600000            # å›å¡«æŒ‡å®šè‚¡ç¥¨
  %(prog)s --stocks stocks.txt               # ä»æ–‡ä»¶è¯»å–è‚¡ç¥¨åˆ—è¡¨
  %(prog)s --resume                          # ç»§ç»­ä¸Šæ¬¡çš„å›å¡«
        """
    )
    parser.add_argument('--start-date', default=None,
                       help='å¼€å§‹æ—¥æœŸ (YYYYMMDD)ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹')
    parser.add_argument('--end-date', default=None,
                       help='ç»“æŸæ—¥æœŸ (YYYYMMDD)ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹')
    parser.add_argument('--stocks', default=None,
                       help='è‚¡ç¥¨åˆ—è¡¨ï¼šé€—å·åˆ†éš”çš„ä»£ç (å¦‚000001,600000)æˆ–æ–‡ä»¶è·¯å¾„(æ¯è¡Œä¸€ä¸ªä»£ç )')
    parser.add_argument('--resume', action='store_true',
                       help='ä»æ£€æŸ¥ç‚¹æ¢å¤')
    parser.add_argument('--checkpoint', default='data/backfill_daily_basic_checkpoint.json',
                       help='æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--skip-existing', action='store_true', default=True,
                       help='è·³è¿‡å·²æœ‰æ•°æ®çš„æ—¥æœŸï¼ˆé»˜è®¤å¯ç”¨ï¼‰')

    args = parser.parse_args()

    # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è·å–token
    try:
        from config.settings import TUSHARE_TOKEN, TUSHARE_DB_PATH
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥é…ç½®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿ config/settings.py å­˜åœ¨å¹¶åŒ…å« TUSHARE_TOKEN")
        return 1

    if not TUSHARE_TOKEN:
        print("âŒ TUSHARE_TOKEN æœªè®¾ç½®ï¼Œè¯·åœ¨ config/settings.py ä¸­é…ç½®")
        return 1

    # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    db = TushareDB(token=TUSHARE_TOKEN, db_path=str(TUSHARE_DB_PATH))

    # è·å–éœ€è¦å›å¡«çš„è‚¡ç¥¨åˆ—è¡¨
    if args.stocks:
        if ',' in args.stocks:
            stock_list = [s.strip() for s in args.stocks.split(',') if s.strip()]
            print(f"ğŸ“‹ ä½¿ç”¨æŒ‡å®šçš„è‚¡ç¥¨åˆ—è¡¨: {len(stock_list)} åª")
        elif Path(args.stocks).exists():
            # æ˜¯æ–‡ä»¶è·¯å¾„
            try:
                with open(args.stocks, 'r') as f:
                    stock_list = [line.strip() for line in f if line.strip()]
                print(f"ğŸ“‹ ä»æ–‡ä»¶è¯»å–äº† {len(stock_list)} åªè‚¡ç¥¨")
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
                return 1
        else:
            # æ˜¯å•ä¸ªè‚¡ç¥¨ä»£ç 
            stock_list = [args.stocks.strip()]
            print(f"ğŸ“‹ ä½¿ç”¨æŒ‡å®šçš„è‚¡ç¥¨: {stock_list[0]}")
    else:
        print("ğŸ” æŸ¥è¯¢éœ€è¦å›å¡«çš„è‚¡ç¥¨...")
        stock_list = get_stocks_need_backfill(db)
        print(f"ğŸ“‹ å…± {len(stock_list)} åªè‚¡ç¥¨éœ€è¦å›å¡« daily_basic æ•°æ®")

    if not stock_list:
        print("âœ… æ²¡æœ‰éœ€è¦å›å¡«çš„è‚¡ç¥¨")
        return 0

    # å°è¯•ä»æ£€æŸ¥ç‚¹æ¢å¤
    start_index = 0
    stats = {'success': 0, 'failed': 0, 'updated': 0, 'total': len(stock_list)}

    if args.resume:
        checkpoint = load_checkpoint(args.checkpoint)
        if checkpoint:
            if checkpoint.get('total') == len(stock_list):
                last_index = checkpoint.get('last_index', 0)
                start_index = last_index + 1
                stats = checkpoint.get('stats', stats)
                print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤: ç¬¬ {start_index + 1} åªè‚¡ç¥¨å¼€å§‹")
            else:
                print("âš ï¸  æ£€æŸ¥ç‚¹ä¸åŒ¹é…ï¼Œä»å¤´å¼€å§‹")
                Path(args.checkpoint).unlink(missing_ok=True)

    # æ˜¾ç¤ºå›å¡«ä¿¡æ¯
    print("=" * 60)
    print("Daily Basic æ•°æ®å›å¡«")
    print("=" * 60)
    print(f"æ€»è‚¡ç¥¨æ•°: {len(stock_list)}")
    if args.start_date:
        print(f"å¼€å§‹æ—¥æœŸ: {args.start_date}")
    if args.end_date:
        print(f"ç»“æŸæ—¥æœŸ: {args.end_date}")
    print(f"è·³è¿‡å·²æœ‰æ•°æ®: {args.skip_existing}")
    print("âš ï¸  APIé¢‘ç‡é™åˆ¶ï¼šæ¯åˆ†é’Ÿ50æ¬¡ï¼Œæ¯æ¬¡é—´éš”1.3ç§’")
    print("=" * 60)
    print()

    # éå†æ¯åªè‚¡ç¥¨
    for i in range(start_index, len(stock_list)):
        symbol = stock_list[i]

        # å®šæœŸæ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯50åªè‚¡ç¥¨ï¼‰
        if (i + 1) % 50 == 1 or i == len(stock_list) - 1:
            print(f"\n{'='*60}")
            print(f"è¿›åº¦: [{i + 1}/{stats['total']}]")
            print(f"æˆåŠŸ: {stats['success']} | å¤±è´¥: {stats['failed']} | å·²æ›´æ–°è®°å½•: {stats['updated']}")
            print(f"{'='*60}")

        try:
            result = backfill_stock(
                db, symbol,
                start_date=args.start_date,
                end_date=args.end_date,
                skip_existing=args.skip_existing
            )

            if result['success']:
                stats['success'] += 1
                stats['updated'] += result['updated']
                if result['updated'] > 0:
                    print(f"âœ… {symbol} æ›´æ–°äº† {result['updated']} æ¡è®°å½•")
                else:
                    print(f"â­ï¸  {symbol} æ— éœ€æ›´æ–°ï¼ˆå·²æœ‰æ•°æ®æˆ–æ— æ–°æ•°æ®ï¼‰")
            else:
                stats['failed'] += 1
                error = result.get('error', 'æœªçŸ¥é”™è¯¯')
                print(f"âŒ {symbol} å¤±è´¥: {error}")

        except Exception as e:
            stats['failed'] += 1
            print(f"âŒ {symbol} å¤„ç†å¤±è´¥: {e}")

        # æ¯10åªè‚¡ç¥¨ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
        if (i + 1) % 10 == 0:
            checkpoint_data = {
                'total': len(stock_list),
                'last_index': i,
                'stats': stats,
                'timestamp': datetime.now().isoformat()
            }
            save_checkpoint(args.checkpoint, checkpoint_data)

    # åˆ é™¤æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼ˆå›å¡«å®Œæˆï¼‰
    if Path(args.checkpoint).exists():
        Path(args.checkpoint).unlink()
        print("ğŸ—‘ï¸  å·²åˆ é™¤æ£€æŸ¥ç‚¹æ–‡ä»¶")

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"Daily Basic æ•°æ®å›å¡«å®Œæˆ:")
    print(f"  æ€»è®¡: {stats['total']} åªè‚¡ç¥¨")
    print(f"  æˆåŠŸ: {stats['success']}")
    print(f"  å¤±è´¥: {stats['failed']}")
    print(f"  æ›´æ–°è®°å½•: {stats['updated']} æ¡")
    print(f"{'='*60}")

    return 0


if __name__ == '__main__':
    exit(main())
